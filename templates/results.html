<div id="results" class="tall banner bgbanner">

    <img src="/static/images/rock.jpg" class="banner-img">
    <div class="vmiddle">Results</div>

</div>
<div class="tall clear">
</div>

<div>
    <h3>Summary of Models</h3>
    <table class="table">
        <tr>
            <th>Model</th>
            <th>Train Accuracy</th>
            <th>Test Accuracy</th>
        </tr>
        <tr>
            <td>Basic Logistic Regression Train on Random Data</td>
            <td>70.07%</td>
            <td>72.21</td>
        </tr>
        <tr>
        <td>Basic Neural Network Train on Random Data</td>
            <td>69.17%</td>
            <td>71.39</td>
        </tr>
        <tr>
            <td>Logistic Regression Trained and Tested on Playlist Specific Songs</td>
            <td>
                96.22%
            </td>
            <td>
                42.5%
            </td>
        </tr>
        <tr>
                <td>Neural Network Trained and Tested on Playlist Specific Songs</td>
                <td>
                    96.22%
                </td>
                <td>
                    42.5%
                </td>
            </tr>
    </table>
    <p>
        Looking at the above table, one thing that immediately jumps out is the second and third rows, both because they have
        very high training accuracy and because they're exactly the same. We used the same set of test and train data on these
        two models and after looking at their predictions, realized they were rejecting nearly every song (only a total of two
        songs were accepted for both). This was a result over overfitting the data. We realized that in taking playlists of over
        length 20, setting aside 1/3 of the songs to classify as 1 and then sampling 50 songs to classify as 0 was overfitting
        our models to predict 0 more often.
    </p>
</div>
6917006421783581
7138895177722436
0.6917006421783581]
Train R2: 0.16527773167183135
17668/17668 [==============================] - 0s 21us/step
Test loss: [0.5637947876231553, 0.7138895177722436]